<!DOCTYPE html>
<html lang="en">

<head>
	<meta http-equiv="content-type" content="text/html; charset=UTF-8">
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    <meta name="keywords" content="CVGIP2016,cvgip2016,cvgip,cvgip 2016,CVGIP 2016,2016,研討會,電腦視覺,CVGIP研討會,CVGIP 研討會,cvgip研討會,cvgip 研討會">
    <meta name="author" content="CVGIP 2016">
	<title>CVGIP 2016 第二十九屆電腦視覺、圖學暨影像處理研討會</title>
	<link rel="stylesheet" type="text/css" href="../js/bootstrap/dist/css/bootstrap.min.css" />
	<link rel="stylesheet" type="text/css" href="../css/style.css" />
	<!--[if lt IE 9]>
		  <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
		  <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
		<![endif]-->
	<script type="text/javascript" src="../js/jquery/dist/jquery.min.js"></script>
	<script type="text/javascript" src="../js/bootstrap/dist/js/bootstrap.min.js"></script>
	<script type="text/javascript" src="../js/script.js"></script>
	<style>
	table, th, td {
    	border: 1px solid black;
    	border-collapse: collapse;
	}
	</style>
</head>

<body>
	<div class="container">
		<img src="../img/banner-new.jpg" id="banner">
		<div class="row">
			<div class="col-lg-3">
				<div class="list-group">
					<a class="list-group-item" href="http://cvgip2016.csie.ntu.edu.tw/"><span>最新消息</span></a>
					<a class="list-group-item" href="../conference_information/">大會資訊</a>
					<a class="list-group-item" href="../conference_organization/">大會組織</a>
					<a class="list-group-item" href="../registration/">線上註冊</a>						
					<a class="list-group-item" href="../most_posters/">科技部成果海報</a>						
					<a class="list-group-item" href="../agenda">會議議程</a>
					<a class="list-group-item" href="../accvworkshop/">視覺前瞻研討會</a>
					<a class="list-group-item" href="../demo/">產學技術發表會</a>												
					<a class="list-group-item" href="../keynote_speaker/">專題演講</a>
					<a class="list-group-item" href="../conference_venue/">大會地點</a>
					<a class="list-group-item" href="../accommodation/">交通住宿</a>
					<a class="list-group-item" href="../travel/">旅遊資訊</a>
					<a class="list-group-item" href="../papers/">論文徵稿</a>	
					<a class="list-group-item" href="../paper_award/">論文獎項</a>									
					<a class="list-group-item" href="../important_dates/">重要時程</a>					
					<a class="list-group-item" href="../sponsors/">贊助廠商</a>
					<a class="list-group-item" href="../coorganizers/">協辦單位</a>
					<a class="list-group-item" href="../contact/">聯絡資訊</a>
				</div>
			</div>
			<div class="col-lg-9" id="content_demo">
				<h3 class="page-header">CVGIP 2016影像/視訊產學技術發表會</h3>

				<h4  class="page-header demo">前言</h4>				
				<p>
					CVGIP 2016 將在 105 年 8 月 15-17 日於基隆長榮桂冠酒店舉辦，會議中除了有近 200 篇的學術論文進行口頭/海報發表及 400 人以上國內相關先進與學生的參與外，本年度將進行一場「影像/視訊產學技術發表會」，就是藉由本次大會大家齊聚一堂的機會，將學術界/研究單位研發有成的「可技轉影像/多媒體技術」向相關廠商發表，形成一個產學雙向溝通的機會與平台。本次大會亦將邀請影像與多媒體的相關廠商來參與這個技術發表會，期望 CVGIP 成為產學媒合的重要平台與推手。
				</p>

				<h4  class="page-header demo">時間、地點</h4>				
				<p>
				1. 時間：105 年 8 月 15 日 (一) 14:00 ~ 17:00<br>
				2. 地點：基隆長榮桂冠酒店 2F 湘雅廳 (基隆市中正路62-1號)
				</p>


				<h4  class="page-header demo">展示技術項目</h4>	
				<table>
				<tr>
					<th width="5%">編號</th>
					<th width="10%">指導教授</th>
					<th width="12%">職稱</th>
					<th width="24%">服務機關</th>
					<th>展示項目</th>
				</tr>
				<tr>
					<td>1</td>
					<td>葉家宏</td>
					<td>教授</td>
					<td>國立中山大學電機工程學系<br>多媒體通訊與訊號處理實驗室</td>
					<td>基於影像處理之先進節能顯示技術</td>
				</tr>
				<tr>
					<td>2</td>
					<td>詹寶珠<br>黃春融</td>
					<td>教授<br>副教授</td>
					<td>成功大學<br>中興大學</td>
					<td>急景流年：摘要影片技術</td>
				</tr>		
				<tr>
					<td>3</td>
					<td>林道通</td>
					<td>教授</td>
					<td>國立臺北大學</td>
					<td>Video Stabilization with Robust Particle Filter and Virtual Camera Movement Trajectory Analysis</td>
				</tr>
				<tr>
					<td>4</td>
					<td>林道通</td>
					<td>教授</td>
					<td>國立臺北大學</td>
					<td>Embedded System Implementation for Vehicle Around View Monitoring</td>
				</tr>		
				<tr>
					<td>5</td>
					<td>吳先晃</td>
					<td>教授</td>
					<td>國立雲林科技大學</td>
					<td>以嵌入式系統及相機陣列建構高爾夫球桿表面瑕疵之自動化檢測</td>
				</tr>	
				<tr>
					<td>6</td>
					<td>徐繼聖</td>
					<td>副教授</td>
					<td>國立台灣科技大學機械系<br>人工視覺實驗室</td>
					<td>Face Recognition Across Illumination, Pose and Expression</td>
				</tr>	
				<tr>
					<td>7</td>
					<td>徐繼聖</td>
					<td>副教授</td>
					<td>國立台灣科技大學機械系<br>人工視覺實驗室</td>
					<td>Facial Attribute Detection with Deep Learning</td>
				</tr>
				<tr>
					<td>8</td>
					<td>徐繼聖</td>
					<td>副教授</td>
					<td>國立台灣科技大學機械系<br>人工視覺實驗室</td>
					<td>Regressive Tree Structured Model for Facial Landmark Localization</td>
				</tr>			
				<tr>
					<td>9</td>
					<td>賴文能</td>
					<td>教授兼系主任</td>
					<td>國立中正大學</td>
					<td>基於單攝影機之即時前車距離估測與適應性巡航控制 (ACC)</td>
				</tr>
				<tr>
					<td>10</td>
					<td>柯建全</td>
					<td>教授</td>
					<td>國立嘉義大學資工系</td>
					<td>應用影像處理與三維重建技術建置乳房磁振造影手術模擬與視覺化系統</td>
				</tr>	
				<tr>
					<td>11</td>
					<td>朱宏國</td>
					<td>副教授</td>
					<td>國立清華大學</td>
					<td>利用稀疏點結構之物件階層影片編輯</td>
				</tr>	
				<tr>
					<td>12</td>
					<td>黃敬群</td>
					<td>助理教授</td>
					<td>國立中正大學</td>
					<td>應用於博物館之訪客定位與追蹤</td>
				</tr>									
				<tr>
					<td>13</td>
					<td>阮聖彰</td>
					<td>教授</td>
					<td>國立臺灣科技大學電子所</td>
					<td>為視障者設技之彩色定位標籤</td>
				</tr>		
				<tr>
					<td>14</td>
					<td>阮聖彰</td>
					<td>教授</td>
					<td>國立臺灣科技大學電子所</td>
					<td>用於有機發光二極體的低功率影像調整技術</td>
				</tr>									
				<tr>
					<td>15</td>
					<td>王家慶</td>
					<td>副教授</td>
					<td>國立中央大學</td>
					<td>運動視覺注意力模型深層遞迴神經網路用於動作辨識</td>
				</tr>		
				<tr>
					<td>16</td>
					<td>王家慶</td>
					<td>副教授</td>
					<td>國立中央大學</td>
					<td>背景物件輪廓引導遮罩模型影像語意分割深層網路</td>
				</tr>
				<tr>
					<td>17</td>
					<td>謝奇文</td>
					<td>副教授</td>
					<td>國立嘉義大學電機系</td>
					<td>用於醫用輻射之多通道皮安培級電流量測與成像系統</td>
				</tr>									
				<tr>
					<td>18</td>
					<td>孫士韋<br>張寶基</td>
					<td>助理教授<br>教授</td>
					<td>國立臺北藝術大學<br>國立中央大學</td>
					<td>多深度攝影機環境之運動動作辨識技術</td>
				</tr>
				<tr>
					<td>19</td>
					<td>周宏隆</td>
					<td>資深技術處長</td>
					<td>華晶集團-聚晶半導體</td>
					<td>Imaging Solution in Mobile Phone</td>
				</tr>									
				<tr>
					<td>20</td>
					<td>陳敦裕</td>
					<td>教授兼系主任</td>
					<td>元智大學</td>
					<td>遠距多人非接觸式生理信號量測</td>
				</tr>									

				</table>


				<h4  class="page-header demo">展示技術摘要</h4>	
				<table>	
				<tr>
					<th width="5%">編號</th>
					<th width="25%">題目</th>
					<th>摘要</th>
				</tr>

				<tr>
				<td>1</td>
				<td>基於影像處理之先進節能顯示技術</td>
				<td>
				無線行動通訊與高畫質顯示技術的持續發展，帶動了使用者對各種行動高畫質影音服務與創新應用程式的需求，也使大尺寸與高解析度螢幕成為市場發展主流。行動裝置中顯示螢幕的耗電居全體元件之冠，考量電池總電量有限以及功能不斷提升所消耗的額外電力，使用時間長短為行動裝置科技領域中極為重要的課題。相較於固定背光面板亮度，動態調整背光面板亮度可有效降低顯示螢幕耗電量；蘋果 iPhone 的自動亮度調整技術即是以光感測器偵測環境亮度做為調整背光亮度的依據。本技術延伸此概念，以影像處理為出發點，發展高能源效率之適應性動態能源管理系統。其根據顯示內容及人類視覺特性將螢幕背光調至適宜亮度，並對特殊顯示狀況例如低對比與亮度等畫面進行補償調整，便能在降低背光亮度的同時依然維持視覺品質。凡是搭載 LCD 之 Android 系統行動裝置皆適合安裝使用，當使用者開啟影像或影片時，可透過啟動節能模式來達到省電目的。目前瀏覽圖片的情況下，平均可減少 17%之耗電量最高可達 24%，而觀看影片時可降低約 25%之耗電量最高可達 28%。
				</td>
				</tr>

				<tr>
				<td>2</td>
				<td>急景流年：摘要影片技術</td>
				<td>
				急景流年可以快速地將監視影片濃縮為短時間的摘要影片，讓使用者無需花費大量時間就可以快速看完長達數十小時的監視影片。在本技術中我們提出Maximum a Posteriori Probability Estimation 以及 Synopsis Table 的方法，突破過去摘要影片只能應用在完整影片的限制，並需要大量運算時間的缺點。隨著監視畫面不斷拍攝，急景流年技術可以線上且即時的進行物體的擷取、追蹤、篩選、重新安排物體在影片中出現的時間點，進而產生摘要影片；以更有效的方式將監視影片呈現給使用者。<br>
				此技術不限定應用的監視系統型式，因此能直接運用於現行的道路監視攝影系統、大樓監視影系統與居家監控系統等等。任何有監視影片事後檢索需求之系統，皆可透過本技術達到提升檢索的目的。
				</td>
				</tr>

				<tr>
				<td>3</td>
				<td>Video Stabilization with Robust Particle Filter and Virtual Camera Movement Trajectory Analysis</td>
				<td>
				The camera stabilization and vibration compensation is an important technology. Nowadays, the use of portable cameras in is widespread, but not all portable cameras are equipped with stabilization system. To reduce the vibration we need apply the post-production procedure. The video vibration compensation relies on the accurate registration between two frames. In order to make the video looks more comfortable and stable, this type of correction may be considered as a problem of image matching. However, we also need to ensure that video fluency upon the correction. In this research, we propose a video stabilization technology, using block matching algorithm to estimate the actual movement trajectory of the camera, and using a Gaussian filter operation to calculate the smoothly virtual movement trajectory, whereby repair vibration video. The goal of our work is to develop a simple algorithm to reduce the complexity of operations and to ensure the stability of the output video.
				</td>
				</tr>


				<tr>
				<td>4</td>
				<td>Embedded System Implementation for Vehicle Around View Monitoring</td>
				<td>
				Traffic safety has become a priority in recent years, and therefore, the field of intelligent transportation surveillance systems has become a major field of research. Among vehicle surveillance systems, the 360。 around view monitor (AVM) system is regarded as the development direction recently. In this research, an proposed; the approach involves rectifying four fisheye cameras and stitching together the four calibrated images obtained from the cameras into one surrounding view image on a low-cost and high portability Android embedded system. To improve the computation performance, the aforementioned procedures are combined into a single step construction mapping using table lookup mechanism and multithreading technique. Through hardware implementation and experiments evaluation, the proposed AVN system performs satisfactorily with surrounding view output frame rate 12fps and the average matching error is as low as 2.89 pixel.
				</td>
				</tr>

				<tr>
				<td>5</td>
				<td>以嵌入式系統及相機陣列建構高爾夫球桿表面瑕疵之自動化檢測</td>
				<td>
				本專題主要是利用 AOI(自動化光學檢測)及嵌入式處理器之應用技術，所開發出一套能有效檢測高爾夫球桿表面瑕疵的系統，由於高爾夫球桿身細長，且有著強烈的反光特性，因此需搭配複數相機才能完成全桿檢測。但為搭配複數相機做檢測，因此需採用極高階的處理器才符合生產效率。因此改採低價但高效能的嵌入式系統與工業相機，先在即時作業系統上完成即時相機取像，再利用影像分析及電腦視覺的技術，完成在嵌入式平台上球桿的自動化瑕疵檢測系統。
				</td>
				</tr>

				<tr>
				<td>6</td>
				<td>Face Recognition Across Illumination, Pose and Expression</td>
				<td>
				本技術旨在進行跨角度以及光源、臉部表情不變性之人臉辨識，相較於其他人臉辨識技術，被限制只能用於正面人臉，而且只要人臉有些許角度、亮度變化或是說話做表情等就會大幅降低辨識能力，主要原因為欠缺多變化性的樣本和傳統的方法難以負荷這些變化性的特徵表現，因此，我們採用卷積類神經網路Convolution Neural Network (CNN)的方法，此方法如同人類大腦的學習，嬰兒一出生就開始學習親人的樣貌並且開始認人，而在嬰兒的眼中就是無數張畫面，畫面中的人可能隨時就轉個頭說說話，甚至是處在不同強度環境光，只要告訴嬰兒這位是爸爸、那位是媽媽，他就能自己去學習原來爸爸長這樣，媽媽長那樣，爸爸擺個鬼臉也仍知道是爸爸，這都是受惠於看過爸爸媽媽無數種變化性，進而學習出來能夠區別爸媽的特徵。所以我們提供大量的人臉資料，這些人臉資料包括有左右旋轉、俯仰角、光源以及表情的變化，有了這些不同變化性的影像資料便能訓練出可應付以上變化的特徵擷取器，可作為一強建的人臉辨識系統，不論是左右的跨角度、上下俯仰角、平面旋轉，照射不同強度光源以及即使受測者作出微笑表情皆可辨識。
				</td>
				</tr>

				<tr>
				<td>7</td>
				<td>Facial Attribute Detection with Deep Learning</td>
				<td>
				我們利用現今非常有效的機器學習方式－深度學習去訓練人臉特徵屬性分類器，深度學習是模仿類神經網路的運算方式，以多節點、多層的概念來學習圖片上的特徵，一開始由較淺的層級學習粗略的特徵，像是線條邊緣，而接著往較深層能學習出更精細的特徵，像是一些簡單形狀，透過更深層，電腦能學出更複雜的形狀或物體，最後電腦能學習到組合重要的特徵，以達到辨識物體的目標，例如：有沒有戴帽子，是否在微笑，是否有鵝蛋臉、雙下巴、鬢角，以及髮型及髮色。
				我們的資料庫是使用 CelebA，其中提供了 40 項人臉特徵屬性，有分男女、髮色、微笑、化妝與穿戴飾品等，我們將其做為資料庫並訓練了 40 個人臉特徵屬性之辨識模型，可用來辨識受測者之性別、是否戴眼鏡、是否有禿頭，以及是否留有鬍子等等。
				</td>
				</tr>

				<tr>
				<td>8</td>
				<td>Regressive Tree Structured Model for Facial Landmark Localization</td>
				<td>
				Tree Structured Model(TSM) 被證實可藉由單一的統一模型同時解決人臉偵測、角度估測與地標點偵測的問題，但其偵測速度於實際系統應用過於緩慢，故我們提出Regressive Tree Structured Model (RTSM) 解決 TSM的偵測速度及地標點定位準確度問題。RTSM 是由雙層式的 TSM 之尺度較小的 coarse TSM (c-TSM)與較精確的 refined TSM(r-TSM) 搭配 Bilateral Support Vector Regression (BSVR)。首先，第一層的 c-TSM 建立在低解析度的影像基礎上，提供粗略但快速的人臉偵測，隨後第二層的 r-TSM 建立在中解析度的影像基礎上，其目的是將 c-TSM所提供的人臉候選區周圍以較準確的模組將其地標點標示出來，接著以 r-TSM所定位出的地標點為基礎，利用順向 BSVR 估測出一組較為稠密地標點，再將順向 BSVR 估測出的地標點使用逆向 BSVR 去重新定位，此時估測出的座標點還具有較大的誤差，為此持續迭代順、逆向 BSVR 直至其誤差收斂，我們藉由在公開資料庫──Multi-PIE、LFPW 與 AFW 測試、與最新的 TSM 相比，可證實其優秀的效能。
				</td>
				</tr>

				<tr>
				<td>9</td>
				<td>基於單攝影機之即時前車距離估測與適應性巡航控制(ACC)</td>
				<td>
				本技術是使用裝置於汽車室內後照後鏡前方之單 webcam 攝影機來進行車道前方車輛之距離估測，再依據所測得距離之瞬時變化驅動本車進行適應性巡航控制(Adaptive Cruise Control, ACC)。本技術僅需單一支攝影機即可進行測距，攝影機可簡易自行安裝，安裝後不需進行複雜之攝影機幾何校正，適用於「車後」市場。本技術可偵測前方 2~50 m 的汽車，經過實驗，其適用於一般天氣、陰天、及輕微雨天(慢中速雨刷)，在高速公路及一般道路下均可適用。本技術已經實際裝設於 Honda CR-V 汽車上進行迴路控制 (closed loop control)，以 Apple Mac 筆電進行影像處理的情形下，每秒可處理 30 張以上的 VGA 圖像 (640x480 pixels)，達到 real-time 的需求。Offline 針對某一高速公路實錄之 9 分鐘連續影片實驗結果，汽車偵測正確率達 99.5%。本技術以車上的 G-sensor 實際量測其迴路控制下的速度變化，證實其即時 ACC 控制下的行車品質良好 (速度不會劇烈變化)。
				</td>
				</tr>

				<tr>
				<td>10</td>
				<td>應用影像處理與三維重建技術建置乳房磁振造影手術模擬與視覺化系統</td>
				<td>
				乳癌是國內常見的女性癌症之一，目前有許多檢測儀器能幫助醫師檢測乳房是否發生病變，由於乳房核磁造影有著高對比的優點，故常被用來描述病人病灶。近年來，乳房核磁造影研究可分為兩大部分：(一)評估乳房緻密度進行乳房區域分割，(二)評估乳房腫塊大小與特徵所進行的腫塊分割，但由於各自使用目的上的不同，因此較少研究將兩分割技術結合。<br>
				臨床上，如能事先幫助醫師了解腫塊在乳房中的大小、位置等資訊，並利用三維視覺化技術，模擬描述乳房與腫塊結構與形狀，便可提供醫師作手術前規劃，例如：穿刺手術的模擬、是否進行乳房切除手術的評估以及後續乳房重建的參考。為符合上述臨床用途，本研究結合了影像處理與三維重建技術，先分割出乳房皮膚邊緣與胸腔基線，建立出三維乳房結構，同時配合影像處理偵測出腫瘤，並將分割結果，以左右乳頭為中心與每一切片邊緣建立出以 90 度間隔的 4 個象限，此手術模擬系統提供了包括：計算腫塊大小、所處象限位置及與皮膚、胸腔、腫瘤與乳頭的距離資訊，為了能進一步清楚了解乳房與腫瘤結構，系統提供乳房與腫塊三維描繪操作介面，以不同角度模擬描繪病患乳房、腫瘤結構與形狀。系統能提供臨床醫師在手術前，針對病灶，評估如何實施病理組織穿刺或是否保留病人乳房的參考。
				</td>
				</tr>

				<tr>
				<td>11</td>
				<td>利用稀疏點結構之物件階層影片編輯</td>
				<td>
				影片為捕捉真實事件的一個方式，現今也已發展出許多先進的影片處理技術，但若無該影片場景之三維模型資訊，則難以直接編輯影片內的物件，而若是希望精確地估計影片中的三維物件資訊，常常需要許多時間、人力和資金。為此我們提出了一個較為簡單的流程，利用使用者所提供的標記以及從影片估算出來的稀疏點雲，便能讓使用者直接編輯影片內的物件，包含改變相機視角、關鍵幀動畫、複製物件，甚至將物件轉移到其他影片。以技術層面來說，首先我們利用使用者標記來分析以 SfM 估算出來之稀疏點雲的簡易型狀結構，並利用此來當成該物件之三維代理幾何，讓使用者能夠直接控制該物件，接著我們提出一個新穎的影像合成演算法，不僅包含能夠維持物體結構的影像變形演算法，還有維持時間以及空間連續性的影片拼貼演算法，再搭配簡易的深度測試、陰影合成和光照調整，便能產生出現存方法難以達成的擬真合成影片，模擬使用者對影片中物件的直接編輯。
				</td>
				</tr>

				<tr>
				<td>12</td>
				<td>應用於博物館之訪客定位與追蹤</td>
				<td>
				本技術中，藉由整合無線訊號強度、慣性元件、影像三種資訊，得知使用者於場景下的位置與行徑路線。接下來，我們將分為兩部分來討論，第一部份為無線訊號定位，使用無線訊號強度與慣性元件來預測使用者位置及路徑，若單純使用Wi-Fi 的定位方法，會因雜訊的干擾及其他因素的影響導致結果不佳；而單純使用慣性元件的定位方法，會因累積誤差使得定位結果產生偏移；如果將上述兩項資訊合併，其定位結果有些微提升。在第二部份稱為影像定位，利用攝影機偵測事先於博物館場景中設置的 QR code，接著利用相機的幾何資訊與 QR code 上的Pattern 特性，推得使用者相對於 QR code 之座標位置。最後，利用 Kalman filter結合無線訊號定位與影像定位之定位資訊，來校正行徑軌跡並降低累積誤差，進行使用者定位。
				</td>
				</tr>

				<tr>
				<td>13</td>
				<td>為視障者設技之彩色定位標籤</td>
				<td>
				我們提出一種專為視障者們使用的彩色標籤，這個標籤是基於 QR code 改良，在外面再增加一圈彩色環，並再中央加入一個輔助用的彩色圓形。基於這個彩色環，我們使用特殊的演算法辨識其中顏色與顏色的邊界，以此為特徵點，並再經過分群、畫外接圓、尋找圓心與半徑與比對之後，就可以尋找出環境中的彩色環，並只針對彩色環的範圍取 ROI 做 QR code 的解碼。我們的演算法有針對嵌入式平台上的硬體如 CPU、GPU 與 DSP 作最佳化，處理時間在一般的智慧型手機下至少能達到一個 1080P 的畫面以 100 微秒完成，相較於普通的 QR code 至少要500 微秒，最少能達到 5 倍的加速，並且我們的標籤還附有遠距離能偵測的特性。當在一段很遠距離偵測到標籤時，裡面的 QR code 並不能被解碼，但我們依據中間的彩色圓形便可以知道這個標籤的種類，我們將這個彩色圓形分成五種並分成五種類的標籤，例如：出入口、廁所、服務中心、房間與電梯。目前我們這個標籤可以運用在手機系統上，會以語音方式提供標籤的資訊。為了視障者們方便使用，也有開發眼鏡型裝置的雛型，藉由與手機連線來辨識標籤。
				</td>
				</tr>


				<tr>
				<td>14</td>
				<td>用於有機發光二極體的低功率影像調整技術</td>
				<td>
				我們提出一種有機發光二極體顯示器的低功率影像調整技術。現今有許多消費性電子產品上都具有顯示螢幕，如手機、平板電腦、智慧手錶等設備，而隨著科技的進步，許多消費者期望追求更好的影像品質，也就是更豐富的色彩影像，為達到這個目的就需要更寬廣的色彩範圍，然而這會使得設備本身消耗更多的功耗。近年來，隨著有機發光二極體的出現，使得影像品質和功率消耗的問題可望被解決，有機發光二極體具有輕薄、全彩高亮度、省電的特性，這在未來的應用上是個趨勢。為了能達到降低功率消耗且不破壞原始影像資料，我們利用直方圖的處理技術來達到此目的。然而在降低功率的同時，可能會使得結果影像產生較差的品質，為此我們設計能將功率消耗和影像對比程度同時做為考慮的目標函式來進行影像處理，使得在減低影像功率消耗的同時，在影像對比度上也具有較佳的品質。另外為了能消除影像中失真的情形，如過度曝光，我們結合過度曝光校正和降低影像功率的技術，使得結果影像能校正影像失真的部分且有效的降低螢幕功率消耗。根據目前的實驗結果，所提的技術最大能降低 75%的螢幕功率消耗且影像也能維持較好的成果。
				</td>
				</tr>

				<tr>
				<td>15</td>
				<td>運動視覺注意力模型深層遞迴神經網路用於動作辨識</td>
				<td>
				基於長短期記憶(Long short-term memory)遞迴神經網路(Recurrent Neural Network)之深層學習(Deep learning)架構，提出運動視覺注意力模型(Motion based visual attention model)。該模型透過擷取影片中的動態資訊，進行影片中的動作辨識。在提出的架構中，影片中的幀影像透過卷積神經網路(Convolutional neural network)進行特徵擷取，並依時序將特徵輸入至運動視覺注意力模型中，產生時序上的序列辨識結果做動作辨識。
				</td>
				</tr>


				<tr>
				<td>16</td>
				<td>背景物件輪廓引導遮罩模型影像語意分割深層網路</td>
				<td>
				基於全卷積神經網路(Fully convolutional neural network)的深層學習(Deep learning)架構，提出背景物件輪廓引導遮罩模型。並以此架構調適為影像語意分割(Image semantic segmentation)網路。該模型藉由影像中較語意更為基礎的資訊作為引導，使得影像語意分割能達到更好的效果，其效果超越許多最先進的系統(State-of-the-art system)表現。
				</td>
				</tr>

				<tr>
				<td>17</td>
				<td>用於醫用輻射之多通道皮安培級電流量測與成像系統</td>
				<td>
				本技術為開發多通道微小電流量測技術。其技術主要可應用於多層式游離腔、質子治療探測器、多葉準直儀等輻射醫學使用。我們主要利用轉阻放大器配合多級電阻，將電流轉成電壓訊號送到後端的類比-數位轉換電路(ADC)，再利用數位訊號處理技術，結合核能研究所提供的劑量轉換因子，可將電流訊號轉成劑量率與相對劑量。<br>
				此外，本技術也提供高壓模組監控以利相關探測器的電壓與電流增益監控，同時也整合溫度環境校正因子，如溫度、氣壓與溼度等。也開發提供單機或是符合PC 顯示功能的人機介面使用。<br>
				目前完成之技術，功能含有:<br>
				a. 可以量測對應 10pA 電流的相對劑量，其不準確率<3%。(完全符合 IEC60580標準訂定)<br>
				b. 擁有極大的電流動態量測電流範圍: 至少 10pA 到 500nA<br>
				c. 量測不確定度: <3% (for DAP< 1μGym2/s); <2% (for DAP>=1μGym2/s)<br>
				d. 可提供至少 16 通道的顯像系統使用。<br>
				e. 可近乎即時監測探測器高壓系統，並回饋高壓模組狀態。<br>
				f. 具有溫度環境修正功能<br>
				g. 具有後送訊號至 PC 功能，與圖形化人機介面。<br>
				h. 通過電檢中心的 EMC, EMI 等電磁輻射安規<br>
				</td>
				</tr>


				<tr>
				<td>18</td>
				<td>多深度攝影機環境之運動動作辨識技術</td>
				<td>
				在本技術中，透過多台深度攝影機，對於單一使用者進行人物偵測，透過多台深度攝影機對於同一使用者之偵測前景資訊，並進行人物骨架分析，此外，對於使用者所手持之物件，進行物件前景偵測。於計算於三維空間所存在之物件之各種統計量後，透過機器學習演算法，進行時間空間特徵向量之學習，所學習得知之高維度空間向量產生之模型，於使用者測試階段中，進行動作分類與動作辨識。在本技術中，透過多重深度攝影機，避免因拍攝角度所造成之遮蔽問題，此外，在本技術展示中，透過 decision level fusion，將多重深度攝影機各自辨識之結果，透過區域無線網路進行綜合辨識結果判斷與呈現，演算複雜度控制於合理範圍中，可進行即時動作辨識結果呈現，將來可應用於運動動作自動教練系統、老人居家照護、嬰幼兒照護等等多種應用領域。
				</td>
				</tr>


				<tr>
				<td>19</td>
				<td>Imaging Solution in Mobile Phone</td>
				<td>
				In recent years, camera solutions become one of the major features in the phone system. In this demonstration, we would like to show you our works using CVGIP technologies to please the end users and bring them better quality in capturing the moments. To introduce and demo<br>
				1. C+M<br>
				2. Real-time Bokeh<br>
				3. Real-time 3D Video
				</td>
				</tr>


				<tr>
				<td>20</td>
				<td>遠距多人非接觸式生理信號量測</td>
				<td>
				在此技術中，我們分成兩個階段實現: 即時人形偵測與呼吸率量測。在人形偵測中，我們提出一個只用深度資訊來達到快速的人形偵測效果。人的正、背面偵測皆可以快速找出。在呼吸率量測方面，偵測紋路顯著區域後，利用光流法取出身體垂直移動量，並以中位數的方法與局部平均濾波得到呼吸信號。之後，利用越零點的方法來高準度計算呼吸率。最後，在實驗中，我們討論了四種量測因子，發現所量測結果是高相關性的。
				</td>
				</tr>

				</table>

			</div>
		</div>
		<div id="top" class="circle" onclick="scrollToTop()"><i class="glyphicon glyphicon-chevron-up"></i></div>
		<div class="copyright">
			<hr>
			Copyright &copy; 2016 National Taiwan University<br>
			版權所有 國立台灣大學 資訊工程學系<br>
			地址：台北市大安區羅斯福路四段1號<br>
			&copy; 2016 National Taiwan University. All Rights Reserved.
		</div>
	</div>
</body>

</html>
